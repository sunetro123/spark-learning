# A list of columns provided, How to know which Combination can be Combo ?

1. Scala take 2 at a time

```
import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.functions._
import scala.collection.JavaConverters._
import scala.util.Try

object PrimaryKeyFinder {
  def main(args: Array[String]): Unit = {
    val spark = SparkSession.builder.appName("PrimaryKeyFinder").getOrCreate()

    // Load your data into a DataFrame (replace 'your_data_source_format' and 'your_data_source_path' with your actual data source)
    val df = spark.read.format("your_data_source_format").load("your_data_source_path")

    // List of columns to check
    val columns = Seq("col1", "col2", "col3", "col4")

    // Function to check uniqueness and non-nullability of a combination of columns
    def isUniqueCombination(df: org.apache.spark.sql.DataFrame, colCombination: Seq[String]): Boolean = {
      val uniqueCount = df.select(colCombination.map(col): _*).distinct().count()
      val totalCount = df.count()
      val nullCount = df.filter(colCombination.map(c => col(c).isNull).reduce(_ || _)).count()
      uniqueCount == totalCount && nullCount == 0
    }

    // Generate all possible combinations of 2 or more columns
    val combinations = (2 to columns.length).flatMap(columns.combinations)
    combinations.foreach { colCombination =>
      if (isUniqueCombination(df, colCombination)) {
        println(s"Combination ${colCombination.mkString(", ")} can be a primary key.")
      }
    }

    spark.stop()
  }
}
```

2. Same in Python

```

from pyspark.sql import SparkSession
from pyspark.sql.functions import col
from itertools import combinations

# Initialize Spark session
spark = SparkSession.builder.appName("PrimaryKeyFinder").getOrCreate()

# Load your data into a DataFrame (replace 'your_data_source' with your actual data source)
df = spark.read.format("your_data_source_format").load("your_data_source_path")

# List of columns to check
columns = ["col1", "col2", "col3", "col4"]

# Function to check uniqueness and non-nullability of a combination of columns
def is_unique_combination(df, col_combination):
    unique_count = df.select(*col_combination).distinct().count()
    total_count = df.count()
    null_count = df.filter(sum(col(c).isNull().cast("int") for c in col_combination) > 0).count()
    return unique_count == total_count and null_count == 0

# Generate all possible combinations of 2 or more columns
for r in range(2, len(columns) + 1):
    for col_combination in combinations(columns, r):
        if is_unique_combination(df, col_combination):
            print(f"Combination {col_combination} can be a primary key.")

# Stop the Spark session
spark.stop()
```
